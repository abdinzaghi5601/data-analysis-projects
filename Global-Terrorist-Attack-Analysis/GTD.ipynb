{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "142a366f-7d7f-490a-9293-abb82f8a0c0f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\abdin\\miniconda3\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\abdin\\miniconda3\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\abdin\\miniconda3\\lib\\site-packages (from pandas) (2.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\abdin\\miniconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\abdin\\miniconda3\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\abdin\\miniconda3\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\abdin\\miniconda3\\lib\\site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\abdin\\miniconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\abdin\\miniconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\abdin\\miniconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#Install and Import Dependencies\n",
    "pip install pandas scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a0e4fa8-9b61-4dd2-bae7-60455bfc37d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the Dataset\n",
    "#Install and Import Dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "703b0a1f-afaa-427f-8371-a0cb767c1e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['eventid', 'iyear', 'imonth', 'iday', 'approxdate', 'extended',\n",
      "       'resolution', 'country', 'country_txt', 'region',\n",
      "       ...\n",
      "       'addnotes', 'scite1', 'scite2', 'scite3', 'dbsource', 'INT_LOG',\n",
      "       'INT_IDEO', 'INT_MISC', 'INT_ANY', 'related'],\n",
      "      dtype='object', length=135)\n",
      "        eventid  iyear  imonth  iday approxdate  extended resolution  country  \\\n",
      "0  197000000001   1970       7     2        NaN         0        NaN       58   \n",
      "1  197000000002   1970       0     0        NaN         0        NaN      130   \n",
      "2  197001000001   1970       1     0        NaN         0        NaN      160   \n",
      "\n",
      "          country_txt  region  ... addnotes scite1 scite2  scite3  dbsource  \\\n",
      "0  Dominican Republic       2  ...      NaN    NaN    NaN     NaN      PGIS   \n",
      "1              Mexico       1  ...      NaN    NaN    NaN     NaN      PGIS   \n",
      "2         Philippines       5  ...      NaN    NaN    NaN     NaN      PGIS   \n",
      "\n",
      "   INT_LOG  INT_IDEO INT_MISC INT_ANY  related  \n",
      "0        0         0        0       0      NaN  \n",
      "1        0         1        1       1      NaN  \n",
      "2       -9        -9        1       1      NaN  \n",
      "\n",
      "[3 rows x 135 columns]\n"
     ]
    }
   ],
   "source": [
    "#Select Relevant Columns\n",
    "#Decide which columns matter for your classification goal. For predicting success (1/0), you might include:\n",
    "\n",
    "#iyear: year\n",
    "#country_txt: country name\n",
    "#region_txt: region name\n",
    "#attacktype1_txt: type of attack (bombing, hijacking, etc.)\n",
    "#targtype1_txt: primary target type\n",
    "#weaptype1_txt: primary weapon type\n",
    "#nkill, nwound: fatalities, wounded\n",
    "#success: (target variable for classification)\n",
    "# Adjust file path as needed\n",
    "df = pd.read_csv(\"globalterrorismdb_0718dist.csv\", encoding='latin-1', low_memory=False)\n",
    "\n",
    "# Quickly explore columns\n",
    "print(df.columns)\n",
    "print(df.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a5d9c5e-cf0b-4e49-ac62-751f7a4a2441",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_needed = [\n",
    "    \"iyear\", \"country_txt\", \"region_txt\", \"attacktype1_txt\",\n",
    "    \"targtype1_txt\", \"weaptype1_txt\", \"nkill\", \"nwound\", \"success\"\n",
    "]\n",
    "\n",
    "df = df[columns_needed].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a7917bc-77b7-4277-8ed6-31915b1a9374",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handle Missing Values\n",
    "#Replace NaN in numeric columns (nkill, nwound) with 0:\n",
    "\n",
    "\n",
    "\n",
    "df[\"nkill\"] = df[\"nkill\"].fillna(0)\n",
    "df[\"nwound\"] = df[\"nwound\"].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ceba5d6-014b-4015-9141-1d1dc8918c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop rows where the target (success) is missing (if any)\n",
    "df.dropna(subset=[\"success\"], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "236fdc03-4fc6-4cca-b2ab-ef345700f0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success\n",
      "1    161632\n",
      "0     20059\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Examine Class Distribution\n",
    "print(df[\"success\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d1eb834-ad3b-441e-b884-e87fb9d9ec01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Features (X) and Target (y)\n",
    "\n",
    "y = df[\"success\"].astype(int)  # Our classification target\n",
    "X = df.drop(\"success\", axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf556887-b7d2-443e-a2d1-4a60fb00d376",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The GTD typically stores descriptive text for columns like country_txt. Machine learning models often need numeric inputs. We can use LabelEncoder or One-Hot Encoding\n",
    "cat_cols = [\"country_txt\", \"region_txt\", \"attacktype1_txt\", \"targtype1_txt\", \"weaptype1_txt\"]\n",
    "for col in cat_cols:\n",
    "    X[col] = X[col].astype(str)        # ensure string type\n",
    "    encoder = LabelEncoder()\n",
    "    X[col] = encoder.fit_transform(X[col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71b596ef-5f75-4a80-af31-3aae0bffb8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Split Data into Training and Test Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "738e1cc0-b504-424a-99ea-4c57cf7bddc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "#Choose and Train a Model\n",
    "#Here, we demonstrate a Random Forest classifier with Grid Search for basic hyperparameter tuning\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# A small parameter grid; expand or refine as needed\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200],\n",
    "    \"max_depth\": [None, 10],\n",
    "    \"min_samples_split\": [2, 5]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    rf, \n",
    "    param_grid,\n",
    "    cv=3,               # 3-fold cross validation\n",
    "    scoring=\"accuracy\", # or 'f1', 'roc_auc', etc.\n",
    "    n_jobs=-1           # use all CPU cores\n",
    ")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "print(\"Best Params:\", grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f46801b-8d07-452c-9356-ff8ba02fa596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9309006852142326\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.54      0.63      3978\n",
      "           1       0.94      0.98      0.96     32361\n",
      "\n",
      "    accuracy                           0.93     36339\n",
      "   macro avg       0.85      0.76      0.80     36339\n",
      "weighted avg       0.92      0.93      0.93     36339\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the Model\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "#Accuracy: percentage of correct predictions.\n",
    "#Classification Report: includes precision, recall, F1-score per class.\n",
    "#If the dataset is imbalanced, focus on F1-score or precision/recall instead of accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6eb7b776-5d17-4d86-9a4e-ee1d8b6ab529",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#If successful attacks far outnumber unsuccessful (or vice versa), you might:\n",
    "\n",
    "#Use class_weight:\n",
    "\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(class_weight=\"balanced\", random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59232300-dc3e-48e1-9791-afd45167fe8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.2628674852197726\n",
      "R^2: 0.29118488108067064\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#For tasks like predicting total casualties (nkill + nwound) or property damage (propvalue):\n",
    "\n",
    "#Replace RandomForestClassifier with RandomForestRegressor (or XGBoost/LightGBM regressors).\n",
    "#Change GridSearchCV scoring to neg_mean_squared_error or r2\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200],\n",
    "    \"max_depth\": [None, 10]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    RandomForestRegressor(random_state=42),\n",
    "    param_grid,\n",
    "    cv=3,\n",
    "    scoring=\"neg_mean_squared_error\"\n",
    ")\n",
    "# ...\n",
    "y_pred = best_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R^2:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c9cf96-93e0-4c4d-8f03-ac7722c236ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63abc70-b87f-4803-99a9-2d6bd42ae76d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
