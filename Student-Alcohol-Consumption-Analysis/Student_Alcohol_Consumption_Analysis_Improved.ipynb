{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Student Alcohol Consumption Analysis\n",
    "\n",
    "## Project Overview\n",
    "This comprehensive analysis explores student alcohol consumption patterns and their relationship with academic performance, demographics, and social factors.\n",
    "\n",
    "**Key Research Questions:**\n",
    "1. How does alcohol consumption vary across different demographic groups?\n",
    "2. What factors most strongly correlate with alcohol consumption?\n",
    "3. Can we predict academic performance based on alcohol consumption patterns?\n",
    "4. What's the relationship between weekday vs weekend drinking patterns?\n",
    "\n",
    "**Dataset:** Portuguese student performance data with 33 features including demographics, family background, school-related features, and alcohol consumption levels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, KFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "# Note: Make sure to download the student-mat.csv file from the UCI repository\n",
    "# URL: https://archive.ics.uci.edu/ml/datasets/Student+Performance\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv('student-mat.csv', sep=';')\n",
    "    print(\"Dataset loaded successfully!\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Dataset file not found. Please download 'student-mat.csv' from UCI repository.\")\n",
    "    print(\"URL: https://archive.ics.uci.edu/ml/datasets/Student+Performance\")\n",
    "    # For demonstration, we'll create a sample dataset structure\n",
    "    print(\"Creating sample dataset for demonstration...\")\n",
    "    \n",
    "# Display basic information\n",
    "print(f\"\\nDataset shape: {df.shape}\")\n",
    "print(f\"\\nColumn names: {list(df.columns)}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive data overview\n",
    "print(\"=== DATASET OVERVIEW ===\")\n",
    "print(f\"Number of students: {len(df)}\")\n",
    "print(f\"Number of features: {len(df.columns)}\")\n",
    "print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024:.2f} KB\")\n",
    "\n",
    "print(\"\\n=== DATA TYPES ===\")\n",
    "print(df.dtypes.value_counts())\n",
    "\n",
    "print(\"\\n=== MISSING VALUES ===\")\n",
    "missing_data = df.isnull().sum()\n",
    "if missing_data.sum() == 0:\n",
    "    print(\"No missing values found!\")\n",
    "else:\n",
    "    print(missing_data[missing_data > 0])\n",
    "\n",
    "print(\"\\n=== BASIC STATISTICS ===\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Comprehensive Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy for preprocessing\n",
    "df_processed = df.copy()\n",
    "\n",
    "# 1. Handle categorical variables consistently\n",
    "print(\"=== PREPROCESSING STEPS ===\")\n",
    "\n",
    "# Binary categorical variables (yes/no)\n",
    "binary_cols = ['schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic']\n",
    "for col in binary_cols:\n",
    "    if col in df_processed.columns:\n",
    "        df_processed[col] = df_processed[col].map({'yes': 1, 'no': 0})\n",
    "\n",
    "# Ordinal categorical variables\n",
    "ordinal_mappings = {\n",
    "    'Medu': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4},  # Mother's education\n",
    "    'Fedu': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4},  # Father's education\n",
    "    'traveltime': {1: 1, 2: 2, 3: 3, 4: 4},  # Travel time\n",
    "    'studytime': {1: 1, 2: 2, 3: 3, 4: 4},   # Study time\n",
    "    'famrel': {1: 1, 2: 2, 3: 3, 4: 4, 5: 5}, # Family relationship\n",
    "    'freetime': {1: 1, 2: 2, 3: 3, 4: 4, 5: 5}, # Free time\n",
    "    'goout': {1: 1, 2: 2, 3: 3, 4: 4, 5: 5},    # Going out\n",
    "    'Dalc': {1: 1, 2: 2, 3: 3, 4: 4, 5: 5},     # Workday alcohol\n",
    "    'Walc': {1: 1, 2: 2, 3: 3, 4: 4, 5: 5},     # Weekend alcohol\n",
    "    'health': {1: 1, 2: 2, 3: 3, 4: 4, 5: 5}    # Health status\n",
    "}\n",
    "\n",
    "# Apply ordinal mappings (if needed)\n",
    "for col, mapping in ordinal_mappings.items():\n",
    "    if col in df_processed.columns:\n",
    "        df_processed[col] = df_processed[col].map(mapping).fillna(df_processed[col])\n",
    "\n",
    "# 2. Create meaningful features\n",
    "print(\"Creating derived features...\")\n",
    "\n",
    "# Alcohol consumption features\n",
    "df_processed['total_alcohol'] = df_processed['Dalc'] + df_processed['Walc']\n",
    "df_processed['alcohol_ratio'] = df_processed['Walc'] / (df_processed['Dalc'] + 0.1)  # Avoid division by zero\n",
    "df_processed['high_alcohol'] = ((df_processed['Dalc'] >= 3) | (df_processed['Walc'] >= 3)).astype(int)\n",
    "df_processed['weekend_drinker'] = (df_processed['Walc'] > df_processed['Dalc']).astype(int)\n",
    "\n",
    "# Academic performance features\n",
    "df_processed['grade_improvement'] = df_processed['G3'] - df_processed['G1']\n",
    "df_processed['grade_consistency'] = df_processed[['G1', 'G2', 'G3']].std(axis=1)\n",
    "df_processed['avg_grade'] = df_processed[['G1', 'G2', 'G3']].mean(axis=1)\n",
    "\n",
    "# Family background features\n",
    "df_processed['parents_edu_avg'] = (df_processed['Medu'] + df_processed['Fedu']) / 2\n",
    "df_processed['edu_gap'] = abs(df_processed['Medu'] - df_processed['Fedu'])\n",
    "\n",
    "# Social features\n",
    "df_processed['social_score'] = df_processed['freetime'] + df_processed['goout']\n",
    "df_processed['support_score'] = df_processed['schoolsup'] + df_processed['famsup']\n",
    "\n",
    "print(f\"Features created. New shape: {df_processed.shape}\")\n",
    "\n",
    "# 3. Handle nominal categorical variables with one-hot encoding\n",
    "nominal_cols = ['school', 'sex', 'address', 'famsize', 'Pstatus', 'Mjob', 'Fjob', 'reason', 'guardian']\n",
    "existing_nominal = [col for col in nominal_cols if col in df_processed.columns]\n",
    "\n",
    "if existing_nominal:\n",
    "    print(f\"One-hot encoding: {existing_nominal}\")\n",
    "    df_processed = pd.get_dummies(df_processed, columns=existing_nominal, drop_first=True)\n",
    "\n",
    "print(f\"Final processed shape: {df_processed.shape}\")\n",
    "print(\"Preprocessing completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Alcohol Consumption Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive alcohol consumption analysis\n",
    "print(\"=== ALCOHOL CONSUMPTION PATTERNS ===\")\n",
    "\n",
    "# Basic statistics\n",
    "print(\"\\n1. Basic Alcohol Consumption Statistics:\")\n",
    "alcohol_stats = df[['Dalc', 'Walc']].describe()\n",
    "print(alcohol_stats)\n",
    "\n",
    "print(f\"\\nWeekday vs Weekend Consumption:\")\n",
    "print(f\"Average weekday consumption: {df['Dalc'].mean():.2f}\")\n",
    "print(f\"Average weekend consumption: {df['Walc'].mean():.2f}\")\n",
    "print(f\"Students with higher weekend consumption: {(df['Walc'] > df['Dalc']).sum()} ({(df['Walc'] > df['Dalc']).mean()*100:.1f}%)\")\n",
    "\n",
    "# Distribution analysis\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Weekday alcohol distribution\n",
    "axes[0,0].hist(df['Dalc'], bins=5, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "axes[0,0].set_title('Weekday Alcohol Consumption Distribution')\n",
    "axes[0,0].set_xlabel('Dalc (1=very low, 5=very high)')\n",
    "axes[0,0].set_ylabel('Number of Students')\n",
    "\n",
    "# Weekend alcohol distribution\n",
    "axes[0,1].hist(df['Walc'], bins=5, alpha=0.7, color='lightcoral', edgecolor='black')\n",
    "axes[0,1].set_title('Weekend Alcohol Consumption Distribution')\n",
    "axes[0,1].set_xlabel('Walc (1=very low, 5=very high)')\n",
    "axes[0,1].set_ylabel('Number of Students')\n",
    "\n",
    "# Comparison boxplot\n",
    "alcohol_data = pd.melt(df[['Dalc', 'Walc']], var_name='Day_Type', value_name='Consumption')\n",
    "sns.boxplot(data=alcohol_data, x='Day_Type', y='Consumption', ax=axes[1,0])\n",
    "axes[1,0].set_title('Weekday vs Weekend Alcohol Consumption')\n",
    "axes[1,0].set_xlabel('Day Type')\n",
    "axes[1,0].set_ylabel('Alcohol Consumption Level')\n",
    "\n",
    "# Correlation between Dalc and Walc\n",
    "axes[1,1].scatter(df['Dalc'], df['Walc'], alpha=0.6, color='purple')\n",
    "axes[1,1].set_title(f'Weekday vs Weekend Alcohol Correlation\\nr = {df[\"Dalc\"].corr(df[\"Walc\"]):.3f}')\n",
    "axes[1,1].set_xlabel('Weekday Alcohol (Dalc)')\n",
    "axes[1,1].set_ylabel('Weekend Alcohol (Walc)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistical test for difference between weekday and weekend consumption\n",
    "t_stat, p_value = stats.ttest_rel(df['Dalc'], df['Walc'])\n",
    "print(f\"\\n2. Statistical Test (Paired t-test):\")\n",
    "print(f\"t-statistic: {t_stat:.4f}\")\n",
    "print(f\"p-value: {p_value:.4f}\")\n",
    "print(f\"Significant difference: {'Yes' if p_value < 0.05 else 'No'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alcohol consumption by demographics\n",
    "print(\"=== ALCOHOL CONSUMPTION BY DEMOGRAPHICS ===\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# By Gender\n",
    "df_gender = df.groupby('sex')[['Dalc', 'Walc']].mean()\n",
    "df_gender.plot(kind='bar', ax=axes[0,0], color=['skyblue', 'lightcoral'])\n",
    "axes[0,0].set_title('Average Alcohol Consumption by Gender')\n",
    "axes[0,0].set_ylabel('Average Consumption')\n",
    "axes[0,0].legend(['Weekday', 'Weekend'])\n",
    "axes[0,0].tick_params(axis='x', rotation=0)\n",
    "\n",
    "# By Age\n",
    "df_age = df.groupby('age')[['Dalc', 'Walc']].mean()\n",
    "df_age.plot(kind='bar', ax=axes[0,1], color=['skyblue', 'lightcoral'])\n",
    "axes[0,1].set_title('Average Alcohol Consumption by Age')\n",
    "axes[0,1].set_ylabel('Average Consumption')\n",
    "axes[0,1].legend(['Weekday', 'Weekend'])\n",
    "axes[0,1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# By Family Size\n",
    "if 'famsize' in df.columns:\n",
    "    df_famsize = df.groupby('famsize')[['Dalc', 'Walc']].mean()\n",
    "    df_famsize.plot(kind='bar', ax=axes[0,2], color=['skyblue', 'lightcoral'])\n",
    "    axes[0,2].set_title('Average Alcohol Consumption by Family Size')\n",
    "    axes[0,2].set_ylabel('Average Consumption')\n",
    "    axes[0,2].legend(['Weekday', 'Weekend'])\n",
    "    axes[0,2].tick_params(axis='x', rotation=0)\n",
    "\n",
    "# By Going Out Frequency\n",
    "df_goout = df.groupby('goout')[['Dalc', 'Walc']].mean()\n",
    "df_goout.plot(kind='bar', ax=axes[1,0], color=['skyblue', 'lightcoral'])\n",
    "axes[1,0].set_title('Alcohol Consumption by Going Out Frequency')\n",
    "axes[1,0].set_ylabel('Average Consumption')\n",
    "axes[1,0].legend(['Weekday', 'Weekend'])\n",
    "axes[1,0].tick_params(axis='x', rotation=0)\n",
    "\n",
    "# By Romantic Relationship\n",
    "df_romantic = df.groupby('romantic')[['Dalc', 'Walc']].mean()\n",
    "df_romantic.plot(kind='bar', ax=axes[1,1], color=['skyblue', 'lightcoral'])\n",
    "axes[1,1].set_title('Alcohol Consumption by Romantic Relationship')\n",
    "axes[1,1].set_ylabel('Average Consumption')\n",
    "axes[1,1].legend(['Weekday', 'Weekend'])\n",
    "axes[1,1].tick_params(axis='x', rotation=0)\n",
    "\n",
    "# By Free Time\n",
    "df_freetime = df.groupby('freetime')[['Dalc', 'Walc']].mean()\n",
    "df_freetime.plot(kind='bar', ax=axes[1,2], color=['skyblue', 'lightcoral'])\n",
    "axes[1,2].set_title('Alcohol Consumption by Free Time')\n",
    "axes[1,2].set_ylabel('Average Consumption')\n",
    "axes[1,2].legend(['Weekday', 'Weekend'])\n",
    "axes[1,2].tick_params(axis='x', rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print some key insights\n",
    "print(\"\\n3. Key Demographic Insights:\")\n",
    "print(f\"Gender differences:\")\n",
    "for gender in df['sex'].unique():\n",
    "    subset = df[df['sex'] == gender]\n",
    "    print(f\"  {gender}: Weekday = {subset['Dalc'].mean():.2f}, Weekend = {subset['Walc'].mean():.2f}\")\n",
    "\n",
    "print(f\"\\nAge-related patterns:\")\n",
    "age_corr_dalc = df['age'].corr(df['Dalc'])\n",
    "age_corr_walc = df['age'].corr(df['Walc'])\n",
    "print(f\"  Age correlation with weekday drinking: {age_corr_dalc:.3f}\")\n",
    "print(f\"  Age correlation with weekend drinking: {age_corr_walc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Academic Performance vs Alcohol Consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Academic performance analysis\n",
    "print(\"=== ACADEMIC PERFORMANCE vs ALCOHOL CONSUMPTION ===\")\n",
    "\n",
    "# Calculate correlations\n",
    "performance_cols = ['G1', 'G2', 'G3', 'absences', 'studytime', 'failures']\n",
    "alcohol_cols = ['Dalc', 'Walc']\n",
    "\n",
    "print(\"\\n1. Correlation Analysis:\")\n",
    "correlation_matrix = df[performance_cols + alcohol_cols].corr()\n",
    "print(\"\\nCorrelations with Alcohol Consumption:\")\n",
    "for perf_col in performance_cols:\n",
    "    dalc_corr = df[perf_col].corr(df['Dalc'])\n",
    "    walc_corr = df[perf_col].corr(df['Walc'])\n",
    "    print(f\"  {perf_col}: Dalc = {dalc_corr:.3f}, Walc = {walc_corr:.3f}\")\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# Grade distributions by alcohol consumption levels\n",
    "# High vs Low alcohol consumption\n",
    "df['high_dalc'] = (df['Dalc'] >= 3).astype(int)\n",
    "df['high_walc'] = (df['Walc'] >= 3).astype(int)\n",
    "\n",
    "# G3 by weekday alcohol\n",
    "df.boxplot(column='G3', by='high_dalc', ax=axes[0,0])\n",
    "axes[0,0].set_title('Final Grade (G3) by Weekday Alcohol Consumption')\n",
    "axes[0,0].set_xlabel('High Weekday Alcohol (0=Low, 1=High)')\n",
    "axes[0,0].set_ylabel('Final Grade (G3)')\n",
    "\n",
    "# G3 by weekend alcohol\n",
    "df.boxplot(column='G3', by='high_walc', ax=axes[0,1])\n",
    "axes[0,1].set_title('Final Grade (G3) by Weekend Alcohol Consumption')\n",
    "axes[0,1].set_xlabel('High Weekend Alcohol (0=Low, 1=High)')\n",
    "axes[0,1].set_ylabel('Final Grade (G3)')\n",
    "\n",
    "# Scatter plot: G3 vs Total Alcohol\n",
    "total_alcohol = df['Dalc'] + df['Walc']\n",
    "axes[0,2].scatter(total_alcohol, df['G3'], alpha=0.6, color='red')\n",
    "axes[0,2].set_title(f'Final Grade vs Total Alcohol Consumption\\nr = {total_alcohol.corr(df[\"G3\"]):.3f}')\n",
    "axes[0,2].set_xlabel('Total Alcohol Consumption (Dalc + Walc)')\n",
    "axes[0,2].set_ylabel('Final Grade (G3)')\n",
    "\n",
    "# Absences by alcohol consumption\n",
    "df.boxplot(column='absences', by='high_dalc', ax=axes[1,0])\n",
    "axes[1,0].set_title('Absences by Weekday Alcohol Consumption')\n",
    "axes[1,0].set_xlabel('High Weekday Alcohol (0=Low, 1=High)')\n",
    "axes[1,0].set_ylabel('Number of Absences')\n",
    "\n",
    "# Study time by alcohol consumption\n",
    "df.boxplot(column='studytime', by='high_walc', ax=axes[1,1])\n",
    "axes[1,1].set_title('Study Time by Weekend Alcohol Consumption')\n",
    "axes[1,1].set_xlabel('High Weekend Alcohol (0=Low, 1=High)')\n",
    "axes[1,1].set_ylabel('Study Time')\n",
    "\n",
    "# Failures by alcohol consumption\n",
    "df.boxplot(column='failures', by='high_walc', ax=axes[1,2])\n",
    "axes[1,2].set_title('Past Failures by Weekend Alcohol Consumption')\n",
    "axes[1,2].set_xlabel('High Weekend Alcohol (0=Low, 1=High)')\n",
    "axes[1,2].set_ylabel('Number of Past Failures')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistical tests\n",
    "print(\"\\n2. Statistical Tests:\")\n",
    "# T-test for grades between high and low alcohol consumers\n",
    "low_dalc_grades = df[df['high_dalc'] == 0]['G3']\n",
    "high_dalc_grades = df[df['high_dalc'] == 1]['G3']\n",
    "t_stat, p_val = stats.ttest_ind(low_dalc_grades, high_dalc_grades)\n",
    "print(f\"Weekday alcohol impact on G3: t={t_stat:.3f}, p={p_val:.4f}\")\n",
    "\n",
    "low_walc_grades = df[df['high_walc'] == 0]['G3']\n",
    "high_walc_grades = df[df['high_walc'] == 1]['G3']\n",
    "t_stat, p_val = stats.ttest_ind(low_walc_grades, high_walc_grades)\n",
    "print(f\"Weekend alcohol impact on G3: t={t_stat:.3f}, p={p_val:.4f}\")\n",
    "\n",
    "# Group analysis\n",
    "print(\"\\n3. Group Performance Analysis:\")\n",
    "print(\"Average G3 by alcohol consumption groups:\")\n",
    "print(f\"  Low weekday alcohol: {low_dalc_grades.mean():.2f}\")\n",
    "print(f\"  High weekday alcohol: {high_dalc_grades.mean():.2f}\")\n",
    "print(f\"  Low weekend alcohol: {low_walc_grades.mean():.2f}\")\n",
    "print(f\"  High weekend alcohol: {high_walc_grades.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Advanced Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced feature engineering for better predictions\n",
    "print(\"=== ADVANCED FEATURE ENGINEERING ===\")\n",
    "\n",
    "# Use the processed dataframe\n",
    "df_features = df_processed.copy()\n",
    "\n",
    "# Create interaction features\n",
    "print(\"Creating interaction features...\")\n",
    "df_features['alcohol_x_goout'] = df_features['total_alcohol'] * df_features['goout']\n",
    "df_features['alcohol_x_freetime'] = df_features['total_alcohol'] * df_features['freetime']\n",
    "df_features['studytime_x_failures'] = df_features['studytime'] * df_features['failures']\n",
    "df_features['absences_x_alcohol'] = df_features['absences'] * df_features['total_alcohol']\n",
    "\n",
    "# Create polynomial features for key variables\n",
    "df_features['studytime_squared'] = df_features['studytime'] ** 2\n",
    "df_features['absences_squared'] = df_features['absences'] ** 2\n",
    "df_features['total_alcohol_squared'] = df_features['total_alcohol'] ** 2\n",
    "\n",
    "# Binning features\n",
    "df_features['age_group'] = pd.cut(df_features['age'], bins=[14, 16, 18, 22], labels=['Young', 'Middle', 'Old'])\n",
    "df_features['grade_category'] = pd.cut(df_features['avg_grade'], bins=[0, 10, 15, 20], labels=['Low', 'Medium', 'High'])\n",
    "\n",
    "# One-hot encode the new categorical features\n",
    "df_features = pd.get_dummies(df_features, columns=['age_group', 'grade_category'], drop_first=True)\n",
    "\n",
    "print(f\"Feature engineering completed. New shape: {df_features.shape}\")\n",
    "\n",
    "# Feature importance analysis using correlation\n",
    "print(\"\\nAnalyzing feature importance...\")\n",
    "numeric_cols = df_features.select_dtypes(include=[np.number]).columns\n",
    "target_correlations = df_features[numeric_cols].corr()['G3'].abs().sort_values(ascending=False)\n",
    "\n",
    "print(\"\\nTop 15 features correlated with G3:\")\n",
    "for i, (feature, corr) in enumerate(target_correlations.head(15).items()):\n",
    "    if feature != 'G3':\n",
    "        print(f\"{i+1:2d}. {feature:25s}: {corr:.3f}\")\n",
    "\n",
    "# Visualize top correlations\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_features = target_correlations.head(16)[1:]  # Exclude G3 itself\n",
    "plt.barh(range(len(top_features)), top_features.values)\n",
    "plt.yticks(range(len(top_features)), top_features.index)\n",
    "plt.xlabel('Absolute Correlation with G3')\n",
    "plt.title('Top 15 Features Correlated with Final Grade (G3)')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Select best features for modeling\n",
    "feature_cols = [col for col in df_features.columns if col not in ['G1', 'G2', 'G3'] and col in numeric_cols]\n",
    "X = df_features[feature_cols]\n",
    "y = df_features['G3']\n",
    "\n",
    "print(f\"\\nSelected {len(feature_cols)} features for modeling.\")\n",
    "print(f\"Target variable (G3) statistics:\")\n",
    "print(f\"  Mean: {y.mean():.2f}\")\n",
    "print(f\"  Std: {y.std():.2f}\")\n",
    "print(f\"  Range: {y.min():.1f} - {y.max():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Machine Learning Models with Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive machine learning pipeline\n",
    "print(\"=== MACHINE LEARNING PIPELINE ===\")\n",
    "\n",
    "# Handle any remaining NaN values\n",
    "X = X.fillna(X.mean())\n",
    "y = y.fillna(y.mean())\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=None)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")\n",
    "\n",
    "# Define models with hyperparameters\n",
    "models = {\n",
    "    'Linear Regression': {\n",
    "        'model': LinearRegression(),\n",
    "        'params': {},\n",
    "        'scaled': False\n",
    "    },\n",
    "    'Ridge Regression': {\n",
    "        'model': Ridge(),\n",
    "        'params': {'alpha': [0.1, 1.0, 10.0, 100.0]},\n",
    "        'scaled': True\n",
    "    },\n",
    "    'Lasso Regression': {\n",
    "        'model': Lasso(),\n",
    "        'params': {'alpha': [0.01, 0.1, 1.0, 10.0]},\n",
    "        'scaled': True\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'model': RandomForestRegressor(random_state=42),\n",
    "        'params': {\n",
    "            'n_estimators': [50, 100, 200],\n",
    "            'max_depth': [None, 10, 20],\n",
    "            'min_samples_split': [2, 5, 10]\n",
    "        },\n",
    "        'scaled': False\n",
    "    },\n",
    "    'Gradient Boosting': {\n",
    "        'model': GradientBoostingRegressor(random_state=42),\n",
    "        'params': {\n",
    "            'n_estimators': [50, 100, 200],\n",
    "            'learning_rate': [0.01, 0.1, 0.2],\n",
    "            'max_depth': [3, 5, 7]\n",
    "        },\n",
    "        'scaled': False\n",
    "    },\n",
    "    'Support Vector Regression': {\n",
    "        'model': SVR(),\n",
    "        'params': {\n",
    "            'C': [0.1, 1.0, 10.0],\n",
    "            'gamma': ['scale', 'auto'],\n",
    "            'kernel': ['rbf', 'linear']\n",
    "        },\n",
    "        'scaled': True\n",
    "    }\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "results = {}\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "print(\"\\nTraining and evaluating models...\")\n",
    "for name, model_config in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    \n",
    "    # Select appropriate data (scaled or unscaled)\n",
    "    if model_config['scaled']:\n",
    "        X_train_use = X_train_scaled\n",
    "        X_test_use = X_test_scaled\n",
    "    else:\n",
    "        X_train_use = X_train\n",
    "        X_test_use = X_test\n",
    "    \n",
    "    # Hyperparameter tuning\n",
    "    if model_config['params']:\n",
    "        grid_search = GridSearchCV(\n",
    "            model_config['model'],\n",
    "            model_config['params'],\n",
    "            cv=cv,\n",
    "            scoring='r2',\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        grid_search.fit(X_train_use, y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "        print(f\"  Best parameters: {grid_search.best_params_}\")\n",
    "    else:\n",
    "        best_model = model_config['model']\n",
    "        best_model.fit(X_train_use, y_train)\n",
    "    \n",
    "    # Cross-validation scores\n",
    "    cv_scores = cross_val_score(best_model, X_train_use, y_train, cv=cv, scoring='r2')\n",
    "    \n",
    "    # Test set predictions\n",
    "    y_pred = best_model.predict(X_test_use)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    results[name] = {\n",
    "        'model': best_model,\n",
    "        'cv_r2_mean': cv_scores.mean(),\n",
    "        'cv_r2_std': cv_scores.std(),\n",
    "        'test_r2': r2,\n",
    "        'test_mae': mae,\n",
    "        'test_rmse': rmse,\n",
    "        'predictions': y_pred\n",
    "    }\n",
    "    \n",
    "    print(f\"  CV R² Score: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "    print(f\"  Test R² Score: {r2:.4f}\")\n",
    "    print(f\"  Test MAE: {mae:.4f}\")\n",
    "    print(f\"  Test RMSE: {rmse:.4f}\")\n",
    "\n",
    "print(\"\\n=== MODEL COMPARISON ===\")\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': results.keys(),\n",
    "    'CV R²': [results[name]['cv_r2_mean'] for name in results.keys()],\n",
    "    'CV R² Std': [results[name]['cv_r2_std'] for name in results.keys()],\n",
    "    'Test R²': [results[name]['test_r2'] for name in results.keys()],\n",
    "    'Test MAE': [results[name]['test_mae'] for name in results.keys()],\n",
    "    'Test RMSE': [results[name]['test_rmse'] for name in results.keys()]\n",
    "})\n",
    "\n",
    "comparison_df = comparison_df.sort_values('Test R²', ascending=False)\n",
    "print(comparison_df.round(4))\n",
    "\n",
    "# Find best model\n",
    "best_model_name = comparison_df.iloc[0]['Model']\n",
    "best_model = results[best_model_name]['model']\n",
    "print(f\"\\nBest performing model: {best_model_name}\")\n",
    "print(f\"Best model Test R²: {results[best_model_name]['test_r2']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Evaluation and Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed model evaluation\n",
    "print(\"=== MODEL EVALUATION AND INSIGHTS ===\")\n",
    "\n",
    "# Model comparison visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# R² comparison\n",
    "model_names = list(results.keys())\n",
    "cv_scores = [results[name]['cv_r2_mean'] for name in model_names]\n",
    "test_scores = [results[name]['test_r2'] for name in model_names]\n",
    "\n",
    "x = np.arange(len(model_names))\n",
    "width = 0.35\n",
    "\n",
    "axes[0,0].bar(x - width/2, cv_scores, width, label='CV R²', alpha=0.8)\n",
    "axes[0,0].bar(x + width/2, test_scores, width, label='Test R²', alpha=0.8)\n",
    "axes[0,0].set_xlabel('Models')\n",
    "axes[0,0].set_ylabel('R² Score')\n",
    "axes[0,0].set_title('Model Performance Comparison')\n",
    "axes[0,0].set_xticks(x)\n",
    "axes[0,0].set_xticklabels(model_names, rotation=45, ha='right')\n",
    "axes[0,0].legend()\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Prediction vs Actual for best model\n",
    "best_predictions = results[best_model_name]['predictions']\n",
    "axes[0,1].scatter(y_test, best_predictions, alpha=0.6, color='blue')\n",
    "axes[0,1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "axes[0,1].set_xlabel('Actual G3')\n",
    "axes[0,1].set_ylabel('Predicted G3')\n",
    "axes[0,1].set_title(f'Predictions vs Actual - {best_model_name}')\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# Residuals plot\n",
    "residuals = y_test - best_predictions\n",
    "axes[1,0].scatter(best_predictions, residuals, alpha=0.6, color='green')\n",
    "axes[1,0].axhline(y=0, color='red', linestyle='--')\n",
    "axes[1,0].set_xlabel('Predicted G3')\n",
    "axes[1,0].set_ylabel('Residuals')\n",
    "axes[1,0].set_title(f'Residuals Plot - {best_model_name}')\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Feature importance (if available)\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': feature_cols,\n",
    "        'importance': best_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False).head(15)\n",
    "    \n",
    "    axes[1,1].barh(range(len(feature_importance)), feature_importance['importance'])\n",
    "    axes[1,1].set_yticks(range(len(feature_importance)))\n",
    "    axes[1,1].set_yticklabels(feature_importance['feature'])\n",
    "    axes[1,1].set_xlabel('Feature Importance')\n",
    "    axes[1,1].set_title(f'Top 15 Feature Importances - {best_model_name}')\n",
    "    axes[1,1].invert_yaxis()\n",
    "elif hasattr(best_model, 'coef_'):\n",
    "    # For linear models, show coefficient magnitudes\n",
    "    coef_importance = pd.DataFrame({\n",
    "        'feature': feature_cols,\n",
    "        'coefficient': np.abs(best_model.coef_)\n",
    "    }).sort_values('coefficient', ascending=False).head(15)\n",
    "    \n",
    "    axes[1,1].barh(range(len(coef_importance)), coef_importance['coefficient'])\n",
    "    axes[1,1].set_yticks(range(len(coef_importance)))\n",
    "    axes[1,1].set_yticklabels(coef_importance['feature'])\n",
    "    axes[1,1].set_xlabel('|Coefficient|')\n",
    "    axes[1,1].set_title(f'Top 15 Coefficient Magnitudes - {best_model_name}')\n",
    "    axes[1,1].invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print detailed insights\n",
    "print(\"\\n=== KEY INSIGHTS ===\")\n",
    "print(f\"\\n1. Model Performance:\")\n",
    "print(f\"   - Best model: {best_model_name}\")\n",
    "print(f\"   - Test R² Score: {results[best_model_name]['test_r2']:.4f}\")\n",
    "print(f\"   - Test MAE: {results[best_model_name]['test_mae']:.4f}\")\n",
    "print(f\"   - Test RMSE: {results[best_model_name]['test_rmse']:.4f}\")\n",
    "\n",
    "print(f\"\\n2. Feature Importance Analysis:\")\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    print(\"   Top 5 most important features:\")\n",
    "    for i, (feature, importance) in enumerate(feature_importance.head(5).values):\n",
    "        print(f\"   {i+1}. {feature}: {importance:.4f}\")\n",
    "elif hasattr(best_model, 'coef_'):\n",
    "    print(\"   Top 5 features with highest coefficient magnitude:\")\n",
    "    for i, (feature, coef) in enumerate(coef_importance.head(5).values):\n",
    "        print(f\"   {i+1}. {feature}: {coef:.4f}\")\n",
    "\n",
    "print(f\"\\n3. Alcohol Consumption Impact:\")\n",
    "alcohol_features = [col for col in feature_cols if 'alc' in col.lower()]\n",
    "if alcohol_features:\n",
    "    print(\"   Alcohol-related features in the model:\")\n",
    "    for feature in alcohol_features:\n",
    "        if hasattr(best_model, 'feature_importances_'):\n",
    "            idx = feature_cols.index(feature)\n",
    "            importance = best_model.feature_importances_[idx]\n",
    "            print(f\"   - {feature}: {importance:.4f}\")\n",
    "        elif hasattr(best_model, 'coef_'):\n",
    "            idx = feature_cols.index(feature)\n",
    "            coef = best_model.coef_[idx]\n",
    "            print(f\"   - {feature}: {coef:.4f}\")\n",
    "\n",
    "print(f\"\\n4. Model Reliability:\")\n",
    "print(f\"   - Cross-validation R² mean: {results[best_model_name]['cv_r2_mean']:.4f}\")\n",
    "print(f\"   - Cross-validation R² std: {results[best_model_name]['cv_r2_std']:.4f}\")\n",
    "print(f\"   - Generalization gap: {abs(results[best_model_name]['cv_r2_mean'] - results[best_model_name]['test_r2']):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Conclusion and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final analysis and recommendations\n",
    "print(\"=== FINAL ANALYSIS AND RECOMMENDATIONS ===\")\n",
    "\n",
    "# Calculate some key statistics for conclusions\n",
    "high_alcohol_students = df[(df['Dalc'] >= 3) | (df['Walc'] >= 3)]\n",
    "low_alcohol_students = df[(df['Dalc'] < 3) & (df['Walc'] < 3)]\n",
    "\n",
    "print(f\"\\n1. DATASET SUMMARY:\")\n",
    "print(f\"   - Total students analyzed: {len(df)}\")\n",
    "print(f\"   - High alcohol consumers: {len(high_alcohol_students)} ({len(high_alcohol_students)/len(df)*100:.1f}%)\")\n",
    "print(f\"   - Low alcohol consumers: {len(low_alcohol_students)} ({len(low_alcohol_students)/len(df)*100:.1f}%)\")\n",
    "print(f\"   - Average final grade (G3): {df['G3'].mean():.2f}\")\n",
    "print(f\"   - Weekend vs weekday drinking preference: {(df['Walc'] > df['Dalc']).sum()} students ({(df['Walc'] > df['Dalc']).mean()*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\n2. KEY FINDINGS:\")\n",
    "print(f\"   a) Academic Performance Impact:\")\n",
    "print(f\"      - High alcohol consumers average G3: {high_alcohol_students['G3'].mean():.2f}\")\n",
    "print(f\"      - Low alcohol consumers average G3: {low_alcohol_students['G3'].mean():.2f}\")\n",
    "print(f\"      - Performance difference: {low_alcohol_students['G3'].mean() - high_alcohol_students['G3'].mean():.2f} points\")\n",
    "\n",
    "print(f\"   b) Alcohol Consumption Patterns:\")\n",
    "print(f\"      - Average weekday consumption: {df['Dalc'].mean():.2f}/5\")\n",
    "print(f\"      - Average weekend consumption: {df['Walc'].mean():.2f}/5\")\n",
    "print(f\"      - Correlation between Dalc and Walc: {df['Dalc'].corr(df['Walc']):.3f}\")\n",
    "\n",
    "print(f\"   c) Demographic Insights:\")\n",
    "male_avg = df[df['sex'] == 'M'][['Dalc', 'Walc']].mean()\n",
    "female_avg = df[df['sex'] == 'F'][['Dalc', 'Walc']].mean()\n",
    "print(f\"      - Male students average alcohol: Dalc={male_avg['Dalc']:.2f}, Walc={male_avg['Walc']:.2f}\")\n",
    "print(f\"      - Female students average alcohol: Dalc={female_avg['Dalc']:.2f}, Walc={female_avg['Walc']:.2f}\")\n",
    "\n",
    "print(f\"   d) Predictive Modeling:\")\n",
    "print(f\"      - Best model: {best_model_name}\")\n",
    "print(f\"      - Prediction accuracy (R²): {results[best_model_name]['test_r2']:.4f}\")\n",
    "print(f\"      - Average prediction error (MAE): {results[best_model_name]['test_mae']:.2f} points\")\n",
    "\n",
    "print(f\"\\n3. RECOMMENDATIONS:\")\n",
    "print(f\"   a) For Educational Institutions:\")\n",
    "print(f\"      - Monitor students with high weekend alcohol consumption (Walc ≥ 3)\")\n",
    "print(f\"      - Implement intervention programs for students showing declining academic performance\")\n",
    "print(f\"      - Focus on students with multiple risk factors (high alcohol + low study time + high absences)\")\n",
    "\n",
    "print(f\"   b) For Prevention Programs:\")\n",
    "print(f\"      - Target male students who show higher alcohol consumption rates\")\n",
    "print(f\"      - Address the strong correlation between going out frequency and alcohol consumption\")\n",
    "print(f\"      - Develop programs that promote healthy social activities\")\n",
    "\n",
    "print(f\"   c) For Further Research:\")\n",
    "print(f\"      - Investigate the temporal relationship between alcohol consumption and academic decline\")\n",
    "print(f\"      - Study the effectiveness of intervention programs on reducing alcohol-related academic issues\")\n",
    "print(f\"      - Explore protective factors that help students maintain good grades despite alcohol consumption\")\n",
    "\n",
    "print(f\"\\n4. LIMITATIONS:\")\n",
    "print(f\"   - Self-reported alcohol consumption data may be subject to bias\")\n",
    "print(f\"   - Cross-sectional data limits causal inference\")\n",
    "print(f\"   - Sample limited to Portuguese students, may not generalize to other populations\")\n",
    "print(f\"   - Alcohol consumption scale (1-5) may not capture fine-grained differences\")\n",
    "\n",
    "print(f\"\\n5. MODEL DEPLOYMENT RECOMMENDATIONS:\")\n",
    "print(f\"   - Use the {best_model_name} model for predicting at-risk students\")\n",
    "print(f\"   - Implement regular model retraining with new data\")\n",
    "print(f\"   - Set up alerts for students with predicted G3 < 10 (failing grade)\")\n",
    "print(f\"   - Combine predictions with human expert judgment for intervention decisions\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYSIS COMPLETED SUCCESSFULLY!\")\n",
    "print(\"This comprehensive analysis provides insights into student alcohol consumption\")\n",
    "print(\"patterns and their relationship with academic performance.\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}