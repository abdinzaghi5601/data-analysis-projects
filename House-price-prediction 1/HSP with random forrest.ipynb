{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62324148-98e9-47a5-a5ee-0b738ad23798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\abdin\\miniconda3\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\abdin\\miniconda3\\lib\\site-packages (from scikit-learn) (2.2.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\abdin\\miniconda3\\lib\\site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\abdin\\miniconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\abdin\\miniconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc3853ca-1ddb-49f9-b347-35a34e3334d9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing value counts (top 10):\n",
      " PoolQC          1453\n",
      "MiscFeature     1406\n",
      "Alley           1369\n",
      "Fence           1179\n",
      "MasVnrType       872\n",
      "FireplaceQu      690\n",
      "LotFrontage      259\n",
      "GarageType        81\n",
      "GarageQual        81\n",
      "GarageFinish      81\n",
      "dtype: int64\n",
      "Validation RMSE: 28922.11135465959\n",
      "Final predictions saved to submissionRandomforest.csv\n"
     ]
    }
   ],
   "source": [
    "# ========== Imports ==========\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# For splitting dataset and searching for best hyperparameters\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# For dealing with missing values\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# For encoding categorical features\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# For applying different transformations to numeric vs. categorical columns\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# For chaining transformations + model into a single workflow\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Our regression model: Random Forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Metric for regression error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "# 1. Load data\n",
    "train = pd.read_csv(\"train.csv\")  # Training data\n",
    "test = pd.read_csv(\"test.csv\")    # Test data (no target column)\n",
    "\n",
    "# Identify the target variable\n",
    "TARGET = \"SalePrice\"\n",
    "\n",
    "# Separate features (X) and target (y) from the training dataset\n",
    "X = train.drop([TARGET], axis=1)  # All columns except SalePrice\n",
    "y = train[TARGET]                 # The SalePrice column alone\n",
    "\n",
    "# 2. Check for missing values (just for reference)\n",
    "missing_counts = X.isna().sum().sort_values(ascending=False)\n",
    "print(\"Missing value counts (top 10):\\n\", missing_counts.head(10))\n",
    "\n",
    "# 3. Handle specific missing values (example):\n",
    "# Fill missing numeric 'LotFrontage' with median\n",
    "X[\"LotFrontage\"] = X[\"LotFrontage\"].fillna(X[\"LotFrontage\"].median())\n",
    "test[\"LotFrontage\"] = test[\"LotFrontage\"].fillna(X[\"LotFrontage\"].median())\n",
    "\n",
    "# Fill missing categorical with \"None\"\n",
    "cat_cols_tmp = X.select_dtypes(include=['object']).columns\n",
    "for col in cat_cols_tmp:\n",
    "    X[col] = X[col].fillna(\"None\")\n",
    "    if col in test.columns:\n",
    "        test[col] = test[col].fillna(\"None\")\n",
    "\n",
    "# 4. Split data into train/validation for local evaluation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y,\n",
    "                                                  test_size=0.2,\n",
    "                                                  random_state=42)\n",
    "\n",
    "# 5. Identify numeric/categorical columns for preprocessing\n",
    "num_cols = X_train.select_dtypes(include=np.number).columns\n",
    "cat_cols = X_train.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Create numeric transformer (median imputer here)\n",
    "numeric_transformer = SimpleImputer(strategy='median')\n",
    "\n",
    "# Create categorical transformer\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='None')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# 6. Combine these into a ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, num_cols),\n",
    "        ('cat', categorical_transformer, cat_cols),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 7. Define the RandomForestRegressor model\n",
    "#    Here, we set a few basic hyperparameters. You can tune further if needed.\n",
    "model = RandomForestRegressor(\n",
    "    n_estimators=100,  # number of trees\n",
    "    random_state=42    # for reproducibility\n",
    ")\n",
    "\n",
    "# 8. Build the Pipeline that first transforms (imputes/encodes) and then trains\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', model)\n",
    "])\n",
    "\n",
    "# 9. Fit (train) the pipeline on the training set\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# 10. Evaluate on the validation set\n",
    "# Make predictions on the validation data\n",
    "y_pred_val = pipeline.predict(X_val)\n",
    "\n",
    "# Calculate validation RMSE\n",
    "val_mse = mean_squared_error(y_val, y_pred_val)\n",
    "val_rmse = np.sqrt(val_mse)\n",
    "print(\"Validation RMSE:\", val_rmse)\n",
    "\n",
    "# 11. [Optional] Hyperparameter Tuning Example (Commented Out)\n",
    "\"\"\"\n",
    "param_grid = {\n",
    "    'model__n_estimators': [50, 100, 200],\n",
    "    'model__max_depth': [None, 10, 20],\n",
    "    'model__min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline, \n",
    "    param_grid, \n",
    "    scoring='neg_root_mean_squared_error', \n",
    "    cv=5,        # 5-fold cross-validation\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Params:\", grid_search.best_params_)\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate best model on validation set\n",
    "val_preds = best_model.predict(X_val)\n",
    "val_rmse_tuned = mean_squared_error(y_val, val_preds, squared=False)\n",
    "print(\"Tuned Validation RMSE:\", val_rmse_tuned)\n",
    "\"\"\"\n",
    "\n",
    "# 12. Retrain on the full dataset for final predictions\n",
    "# (Comment out the above if using the tuned model from grid search)\n",
    "pipeline.fit(X, y)\n",
    "\n",
    "# 13. Predict on the test set\n",
    "test_preds = pipeline.predict(test)\n",
    "\n",
    "# 14. Save predictions to a CSV if needed\n",
    "output = pd.DataFrame({'Id': test['Id'], 'SalePrice': test_preds})\n",
    "output.to_csv('submission.csv', index=False)\n",
    "print(\"Final predictions saved to submissionRandomforest.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5210d764-55ff-4035-acee-bb927ebaf365",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f861669-edc5-44c2-98e9-bc96a6cf4596",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
